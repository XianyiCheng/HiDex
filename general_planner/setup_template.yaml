# ---- Environment Setup ----

# The object can be created as using primitive shapes or from mesh file (mesh_object). 
# Keep one object only. Comment the ones you don't need. 

box_object:
  shape: [1,1,1]
  contact_file: "/data/box_l1.csv" # path to sampled surface points on cube of unit half length
  negate_contact_normal: false # contact normals should point inwards, compare this with the contact_file and decide whether to negate the contact normal
  # disabled_normal_directions: [[0,0,-1], [0,0,1]]

ellipsoid_object:
  semi_axis: [1,1,1]
  contact_file: "/data/ellipsoid_unit_semi_axis.csv" # path to sampled surface points on ellipsoid of unit semi-axis
  negate_contact_normal: false # contact normals should point inwards, compare this with the contact_file and decide whether to negate the contact normal
  # disabled_normal_directions: [[0,0,-1], [0,0,1]]

cylinder_object:
  radius: 1
  height: 2
  contact_file: "/data/cylinder_r1_h1.csv" # path to sampled surface points on cylinder of unit radius and unit height
  negate_contact_normal: false # contact normals should point inwards, compare this with the contact_file and decide whether to negate the contact normal
  # disabled_normal_directions: [[0,0,-1], [0,0,1]]

# mesh_object:
#   mesh_file: "path_to_mesh.stl"
#   scale: 1.0
#   contact_file: "path_to_sampled_surface_points.csv" # "none" if there is no presampled contact file, in which case the contact points will be sampled on the fly
#   negate_contact_normal: false
# disabled_normal_directions: [[0,0,-1], [0,0,1]]

maximum_surface_contact_points: 100

environment: # maximum 20 blocks
  block_1:
    dimension: [20,20,1]
    location: [0,0,-0.5]
  block_2:
    dimension: [4,5,4]
    location: [-4.50001, 0, 1]
  cylinder_1:
    radius: 1
    height: 1
    location: [1,0,2]
  ellipsoid_1:
    dimension: [1,1,1] # semi-axis
    location: [0,0,2]

characteristic_length: 1

robot_object_friction_coefficient: 0.8
environment_object_friction_coefficient: 0.4

task_dynamics: "quasidynamic" # "quasistatic", "quasidynamic", "none", "force_closure"
object_weight: [0,0,-1,0,0,0]
object_inertia: 
  [ 1, 0, 0, 0, 0, 0, 
    0, 1, 0, 0, 0, 0, 
    0, 0, 1, 0, 0, 0, 
    0, 0, 0, 0.167, 0, 0, 
    0, 0, 0, 0, 0.167, 0, 
    0, 0, 0, 0, 0, 0.167 ]

# ---- Robot ----

free_sphere_robot: 
  number_of_contacts: 1
  radius: 0.1
  patch_contact: true # false for point contacts
  # workspace_limits: # comment this out if there is no limits
  #   # [x_min, x_max, y_min, y_max, z_min, z_max]
  #   box_1: [-10,10,-10,10,-10,10]

# delta_array:
#   finger_radius: 0.5
#   workspace_radius: 2.4
#   workspace_height: 10
#   patch_contact: true
#   locations:
#     robot_1: [4.3301, -3.75, 0]
#     robot_2: [4.3301, -7.5, 0]
#     robot_3: [4.3301, -11.25, 0]
#     robot_4: [8.6602, -5.915, 0]
#     robot_5: [8.6602, -9.665, 0]

# dexterous_direct_drive_hand:
#   To_Be_Implemented: 1

 

# ---- Start and Goal Pose ----
# pose [x, y, z, qx, qw, qz, qw]
object_start_pose: [-0.1,0,0.5,0,0,0,1]
object_goal_pose: [0.7,0,0.5,0,0.7071,0,0.7071]

# ---- Run options ----
random_seed: -1

# ---- Planner options ----

refine_object_trajectory: # whether to refine the trajectory for 2nd level search
  enabled: false
  distance: 0.05

transition_pruning: false

rrt_options:
  max_samples: 50
  goal_biased_prob: 1.0
  goal_thr: 0.174
  extend_epsilon:
    translation: 0.5
    rotation_degree: 120
  weight:
    rotation: 1
    translation: 0.1
  sample:
    position_upper_bound: [1,2,2]
    position_lower_bound: [1,2,3]
    rotation: 
      SO3_enabled: true
      axis: [0,0,1] # if SO3_enabled is false, sample rotation on this axis
  search_with_manipulator_config: false # whether to save manipulator config in the search (and the search will consider manipulator config as well)

mcts_options:
  max_time: 5
  l1_1st_max_iterations: 10
  l1_max_iterations: 1
  l2_1st_max_iterations: 10
  l2_max_iterations: 1
  final_l2_1st_max_iterations: 20
  final_l2_max_iterations: 5

# ---- Reward and Probability ----
grasp_measure_charac_length: -1.0 # <0, disable grasp measure

level_1_reward: "CMGLevel1Reward"
level_2_reward: "CMGLevel2Reward"

# "inhand" (must have workspace limit) or "env"
action_probability_L2: "env"

# ---- Output and Visualization ----

# visualization options: 
# "csv": show the trajecotry in the result csv file in save_file_path
# "setup": show the task setup
# "save": plan a trajectory, saved in csv, no visualization
# "show": plan a trajectory and show, don't save in the csv
# "save_n_show": plan a trajectory, saved in csv, and show the results

visualize_option: "setup"
save_file_path: "/general_planner/path_to_output.csv"