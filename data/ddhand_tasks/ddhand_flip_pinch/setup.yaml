# ---- Object Setup ----

box_object:
  shape: [3.4,3.4,1]
  contact_file: "assets/box_l1_2D.csv" # Relative path in the task folder to the file of sampled surface points on a cube of unit length. We will automatically scale the contact points according to the shape.
  negate_contact_normal: false # Contact normals should point inwards. Compare this with the contact_file and decide whether to negate the contact normal.
  # disabled_normal_directions: [[0,0,-1], [0,0,1]] # If you want to disable some contact points on the object using contact normal directions (pointing inward to the object surface), specify them here. 

maximum_surface_contact_points: 100 # Maximum number of contact points to sample on the object surface

# ---- Environment Setup ----

environment: 
  block_1:
    dimension: [20,20,1]
    location: [0,0,-0.5]

characteristic_length: 1

robot_object_friction_coefficient: 0.8
environment_object_friction_coefficient: 0.4

task_dynamics: "quasidynamic" # "quasistatic", "quasidynamic", "none", "force_closure"
object_weight: [0,0,-0.1,0,0,0]
object_inertia: 
  [ 0.1, 0, 0, 0, 0, 0, 
    0, 0.1, 0, 0, 0, 0, 
    0, 0, 0.1, 0, 0, 0, 
    0, 0, 0, 0.0167, 0, 0, 
    0, 0, 0, 0, 0.0167, 0, 
    0, 0, 0, 0, 0, 0.0167 ]

# ---- Robot ----

fixed_ddhand:
  hand_pose: [0,0,8.3,0,0,0,1]
  finger_type: "horizontal" # "horizontal" or "vertical" 
  scale: 100 # We prefer centimeter as the unit, while inside ddhand, the unit is meter. So we scale up 100 times.
  relocation_distance_to_surface: 0.8
  calibration_location: [-1.7, 0, 0.5] # world frame
  default_locations: # world frame
    finger_1: [-1, 0, 1]
    finger_2: [1, 0, 1]
 
# ---- Start and Goal Pose ----
# A pose is specified by the position and quaternion: [x, y, z, qx, qy, qz, qw].
object_start_pose: [0,0,0.5,0,0,0,1]
object_goal_pose: [0,0,0.5,0,-1,0,0]

# ---- Run options ----
random_seed: -1

# ---- Planner options ----

refine_object_trajectory: # whether to refine the trajectory for 2nd level search
  enabled: true
  distance: 0.1

transition_pruning: false

rrt_options:
  max_samples: 50
  goal_biased_prob: 0.8
  goal_thr: 0.5
  extend_epsilon:
    translation: 0.5
    rotation_degree: 120
  weight:
    rotation: 1
    translation: 0.5
  sample:
    position_upper_bound: [1,0,3.5]
    position_lower_bound: [-1.7,0,0]
    rotation: 
      SO3_enabled: false
      axis: [0,1,0] # if SO3_enabled is false, sample rotation on this axis
  search_with_manipulator_config: false # whether to save manipulator config in the search (and the search will consider manipulator config as well)

mcts_options:
  max_time: 5
  l1_1st_max_iterations: 10
  l1_max_iterations: 1
  l2_1st_max_iterations: 20
  l2_max_iterations: 5
  final_l2_1st_max_iterations: 20
  final_l2_max_iterations: 5

# ---- Reward and Probability ----
grasp_measure_charac_length: -1 # <0, disable grasp measure

level_1_reward: "CMGLevel1Reward"
level_2_reward: "CMGLevel2Reward"

# "inhand" (must have workspace limit) or "env"
action_probability_L2: "env"

# ---- Output and Visualization ----

# Visualization options: 
# "csv": show the trajecotry in the in output.csv under the task folder. Press space to play the trajectory.
# "setup": show the task setup. Press space to show start and goal poses.
# "save": plan a trajectory, saved in output.csv, no visualization
# "show": plan a trajectory and show
visualize_option: "csv"